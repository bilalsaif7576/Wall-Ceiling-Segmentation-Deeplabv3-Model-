{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import React, { useEffect, useState } from 'react';\n",
    "import { View, Text, Button, Image as RNImage } from 'react-native';\n",
    "import { NativeModules } from 'react-native';\n",
    "import ImagePicker from 'react-native-image-picker';\n",
    "import RNFS from 'react-native-fs';\n",
    "import Canvas from 'react-native-canvas';\n",
    "import ImageResizer from 'react-native-image-resizer'; // Added for native resizing\n",
    "\n",
    "const { TFLite } = NativeModules;\n",
    "\n",
    "const WallCeilingSegmentation = () => {\n",
    "  const [modelLoaded, setModelLoaded] = useState(false);\n",
    "  const [prediction, setPrediction] = useState(null);\n",
    "\n",
    "  // Load TFLite model\n",
    "  useEffect(() => {\n",
    "    async function loadModel() {\n",
    "      try {\n",
    "        const modelPath = 'assets/Final_Wall_Segmentation.tflite'; // Changed: Match optimized model file\n",
    "        await TFLite.loadModel(modelPath);\n",
    "        TFLite.setUseNNAPI(true); // Added: Enable NNAPI for int8 quantization speedup\n",
    "        TFLite.setNumThreads(4); // Added: Optimize CPU usage for mid-range devices\n",
    "        setModelLoaded(true);\n",
    "        console.log('Model loaded successfully');\n",
    "      } catch (error) {\n",
    "        console.error('Model loading error:', error);\n",
    "      }\n",
    "    }\n",
    "    loadModel();\n",
    "  }, []);\n",
    "\n",
    "  // Preprocess and predict\n",
    "  async function predict() {\n",
    "    if (!modelLoaded) {\n",
    "      console.log('Model not loaded');\n",
    "      return;\n",
    "    }\n",
    "\n",
    "    try {\n",
    "      // Pick image\n",
    "      let response;\n",
    "      try {\n",
    "        response = await ImagePicker.launchImageLibrary({\n",
    "          mediaType: 'photo',\n",
    "          includeBase64: false, // Changed: Disable base64 for efficiency\n",
    "        });\n",
    "      } catch (error) {\n",
    "        console.error('ImagePicker error:', error);\n",
    "        return;\n",
    "      }\n",
    "\n",
    "      if (response.didCancel || !response.assets) {\n",
    "        console.log('Image selection cancelled');\n",
    "        return;\n",
    "      }\n",
    "\n",
    "      const imageUri = response.assets[0].uri;\n",
    "\n",
    "      // Resize image natively to 224x224\n",
    "      const resizedImage = await ImageResizer.createResizedImage(\n",
    "        imageUri,\n",
    "        224, // Changed: Match model’s 224x224 input\n",
    "        224,\n",
    "        'JPEG',\n",
    "        100, // Quality\n",
    "        0, // Rotation\n",
    "        undefined, // Temp file\n",
    "        false, // Keep metadata\n",
    "        { mode: 'stretch' } // Resize mode\n",
    "      );\n",
    "\n",
    "      // Read resized image\n",
    "      const imageData = await RNFS.readFile(resizedImage.uri, 'base64');\n",
    "      const image = new RNImage();\n",
    "      image.src = data:image/jpeg;base64,${imageData};\n",
    "      await new Promise((resolve) => {\n",
    "        image.onload = resolve;\n",
    "      });\n",
    "\n",
    "      // Draw to canvas for pixel access\n",
    "      const canvas = new Canvas(224, 224);\n",
    "      const ctx = canvas.getContext('2d');\n",
    "      ctx.drawImage(image, 0, 0, 224, 224);\n",
    "      const pixelData = ctx.getImageData(0, 0, 224, 224);\n",
    "      const pixels = pixelData.data;\n",
    "\n",
    "      // Convert to Uint8Array (0–255)\n",
    "      const inputBuffer = new Uint8Array(224 * 224 * 3);\n",
    "      for (let i = 0, j = 0; i < pixels.length; i += 4, j += 3) {\n",
    "        inputBuffer[j] = pixels[i]; // R\n",
    "        inputBuffer[j + 1] = pixels[i + 1]; // G\n",
    "        inputBuffer[j + 2] = pixels[i + 2]; // B\n",
    "      }\n",
    "\n",
    "      // Run prediction with timing\n",
    "      const start = Date.now(); // Added: Measure inference time\n",
    "      const output = await TFLite.run(inputBuffer);\n",
    "      console.log(Inference time: ${Date.now() - start}ms); // Added: Verify ~1s inference\n",
    "\n",
    "      if (!output || output.length !== 224 * 224 * 3) {\n",
    "        throw new Error(Invalid output length: expected ${224 * 224 * 3}, got ${output?.length});\n",
    "      }\n",
    "\n",
    "      // Process output (uint8, matches int8 quantization)\n",
    "      const outputArray = new Uint8Array(output);\n",
    "      const mask = new Uint8Array(224 * 224);\n",
    "      for (let i = 0; i < 224 * 224; i++) {\n",
    "        const probs = outputArray.slice(i * 3, i * 3 + 3);\n",
    "        mask[i] = probs.indexOf(Math.max(...probs)); // argmax: 0, 1, or 2\n",
    "      }\n",
    "\n",
    "      // Visualize mask\n",
    "      const colorMap = {\n",
    "        0: [0, 0, 255], // Background: Blue\n",
    "        1: [0, 255, 0], // Wall: Green\n",
    "        2: [255, 0, 0], // Ceiling: Red\n",
    "      };\n",
    "      const maskImage = new Uint8Array(224 * 224 * 4);\n",
    "      for (let i = 0; i < mask.length; i++) {\n",
    "        const classId = mask[i];\n",
    "        maskImage[i * 4] = colorMap[classId][0];\n",
    "        maskImage[i * 4 + 1] = colorMap[classId][1];\n",
    "        maskImage[i * 4 + 2] = colorMap[classId][2];\n",
    "        maskImage[i * 4 + 3] = 255;\n",
    "      }\n",
    "\n",
    "      setPrediction(maskImage);\n",
    "      console.log('Prediction completed');\n",
    "\n",
    "      // Clean up temporary file\n",
    "      if (resizedImage.uri) {\n",
    "        await RNFS.unlink(resizedImage.uri).catch((err) => console.warn('Failed to delete temp file:', err));\n",
    "      }\n",
    "\n",
    "    } catch (error) {\n",
    "      console.error('Prediction error:', error);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return (\n",
    "    <View style={{ flex: 1, justifyContent: 'center', alignItems: 'center' }}>\n",
    "      <Text>Wall & Ceiling Segmentation</Text>\n",
    "      {modelLoaded ? <Text>Model Ready</Text> : <Text>Loading Model...</Text>}\n",
    "      {prediction && (\n",
    "        <Canvas ref={(canvas) => {\n",
    "          if (canvas) {\n",
    "            const ctx = canvas.getContext('2d');\n",
    "            const imageData = ctx.createImageData(224, 224);\n",
    "            imageData.data.set(prediction);\n",
    "            ctx.putImageData(imageData, 0, 0);\n",
    "          }\n",
    "        }} style={{ width: 224, height: 224 }} />\n",
    "      )}\n",
    "      <Button title=\"Select Image and Predict\" onPress={predict} />\n",
    "    </View>\n",
    "  );\n",
    "};\n",
    "\n",
    "export default WallCeilingSegmentation;\n",
    "\n",
    "// Optional: For real-time camera feed with VisionCamera\n",
    "/*\n",
    "import { Camera } from 'react-native-vision-camera';\n",
    "const frameProcessor = (frame) => {\n",
    "  const buffer = frame.toRGB(); // Pseudo-code: Convert frame to RGB\n",
    "  const inputBuffer = new Uint8Array(224 * 224 * 3);\n",
    "  // Copy buffer (resize to 224x224)\n",
    "  const output = TFLite.runSync(inputBuffer); // Synchronous for real-time\n",
    "  // Process output and update UI\n",
    "};\n",
    "*/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
